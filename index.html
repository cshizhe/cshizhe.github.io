<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Shizhe Chen (Renmin University of China)</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

  <!-- Custom styles for this template -->
  <link href="css/agency.css" rel="stylesheet">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">Shizhe Chen</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav text-uppercase ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#news">News</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#publication">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#services">Services</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Header -->
  <header class="masthead">
    <div class="container">
      <div class="intro-text">
        <div class="intro-lead-in"></div>
        <div class="intro-heading text-uppercase"></div>
        <!-- <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#services">Tell Me More</a> -->
      </div>
    </div>
  </header>

  <!-- About Me -->
  <section class="page-section" id="about">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading text-uppercase">About</h2>
          <h3 class="section-subheading text-muted"></h3>
        </div>
      
        <div class="col-md-3 panel">
          <img src="./img/about/photo_of_me.jpg" width="100%">
          <p class="text-muted"> email: cshizhe at gmail dot com </p>
          <!-- <img src="./img/profilepic.jpg" width="100%" class="front card"> -->
          <!-- <img src="./img/IMG_0517_4.png" width="100%" class="back card text-center"> -->
        </div>
        <div class="col-md-9">
            <p class="text-muted">My name is Shizhe Chen. I am a fifth-year PhD student at Renmin University of China, advised by <a target="_blank" href="http://jin-qin.com/">Prof. Qin Jin</a>. My CV can be found <a target="_blank" href="pdfs/cshizhe_resume.pdf">here</a>.

            <br> <br> My research interests are vision-and-language, video understanding, affective computing and multimodal deep learning.
<!--             <br> <br> My research goal is to make human-machine interactions more natural, such as enable machine to communicate in natural language sentences about the world and understand human emotions.
 -->
            <br> <br>I received my B.S degree from Renmin University of China in 2015. I have visited Carnegie Mellon University in 2018 advised by <a target="_blank" href="https://www.cs.cmu.edu/~alex/">Prof. Alexander Hauptmann</a>, and University of Adelaide in 2019 advised by <a target="_blank" href="http://www.qi-wu.me/home.html">Prof. Qi Wu</a>. I worked at MSRA with <a target="_blank" href="https://jianlong-fu.github.io/">Jianlong Fu</a> and <a target="_blank" href="https://www.microsoft.com/en-us/research/people/rsong/">Ruihua Song</a> in 2019. I also received the Baidu Scholarship in 2017.
              
            </p>

            <p>[<a target="_blank" href="https://scholar.google.com/citations?user=wZhRRy0AAAAJ&hl=en">Google Scholar</a>] [<a target="_blank" href="https://github.com/cshizhe">GitHub</a>] [<a target="_blank" href="https://www.linkedin.com/in/shizhe-chen-71542291/">Linkedin</a>]</p>
        
        </div>
      </div>
    </div>
  </section>


  <!-- News -->
  <section class="page-section" id="news">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
            <h2 class="section-heading">News</h2>
        </div><br> <br>
      </div>

      <div class="row">
        <div class="col-md-3 text-muted text-right">04/2020</div>
        <div class="col-md-6 text-muted">We are organizing <a target="_blank" href="https://languageandvision.github.io/youmakeup_vqa/index.html">YouMakeup VQA Challenge</a> at CVPR 2020 for fine-grained action understanding!</div>
        <div class="col-md-3 text-muted">[<a target="_blank" href="https://arxiv.org/abs/2004.05573">PDF</a>][<a target="_blank" href="https://github.com/AIM3-RUC/Youmakeup_Baseline">Code</a>]</div>
      </div>

      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">03/2020</div>
        <div class="col-md-6 text-muted">Two papers (1 oral and 1 poster) accepted by <a target="_blank" href="http://cvpr2020.thecvf.com">CVPR 2020</a>.</div>
      </div>

      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">11/2019</div>
        <div class="col-md-6 text-muted">Our team is the winner of <a target="_blank" href="https://www-nlpir.nist.gov/projects/tv2019/vtt.html">NIST Trecvid 2019 Video to Text Task</a>.</div>
      </div>

      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">10/2019</div>
        <div class="col-md-6 text-muted">Our team achieves the second place in <a target="_blank" href="http://vatex.org/main/index.html">ICCV 2019 VATEX Video Captioning Challenge</a>.</div>
        <div class="col-md-3 text-muted">[<a target="_blank" href="https://arxiv.org/abs/1910.06737">PDF</a>]</div>
      </div>

      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">08/2019</div>
        <div class="col-md-6 text-muted">We have three papers accepted by <a target="_blank" href="https://www.acmmm.org/2019/">ACM Multimedia 2019</a>!</div>
        <!-- <div class="col-md-3 text-muted">[<a target="_blank" href="https://arxiv.org/abs/1901.02860">PDF</a>]</div> -->
      </div>
      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">08/2019</div>
        <div class="col-md-6 text-muted">Our paper "YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension" has been accepted by EMNLP 2019 and the dataset is released.</a></div>
        <div class="col-md-3 text-muted">[<a target="_blank" href="https://www.aclweb.org/anthology/D19-1517/">PDF</a>] [<a target="_blank" href="https://github.com/AIM3-RUC/YouMakeup">Data</a>]</div>
      </div>
      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">06/2019</div>
        <div class="col-md-6 text-muted">Our team is the winner of <a target="_blank" href="http://activity-net.org/challenges/2019">CVPR 2019 ActivityNet Dense Video Captioning Task.</a></div>
        <div class="col-md-3 text-muted">[<a target="_blank" href="https://arxiv.org/abs/1907.05092">PDF</a>]</div>
      </div>
      <br>
      
      <div class="row">
        <div class="col-md-3 text-muted text-right">05/2019</div>
        <div class="col-md-6 text-muted">Our paper "From Words to Sentences: A Progressive Learning Approach for Zero-resource Machine Translation with Visual Pivots" has been accepted by IJCAI 2019.</a></div>
        <div class="col-md-3 text-muted">[<a target="_blank" href="https://arxiv.org/abs/1906.00872">PDF</a>]</div>
      </div>
      <br>

      <div class="row">
        <div class="col-md-3 text-muted text-right">01/2019</div>
        <div class="col-md-6 text-muted">Our paper "Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal Data" has been accepted by AAAI 2019.</a></div>
        <div class="col-md-3 text-muted">[<a target="_blank" href="https://arxiv.org/abs/1906.00378">PDF</a>]</div>
      </div>
      <br>
      

      <!-- <br> <br>

      <div class="row">
        <div class="col-md-6 text-muted text-right"><a target="_blank" href="archive.html">View more...</a></div>
      </div> -->

    </div>
  </section>

  <!-- Publication -->
  <section class="page-section" id="publication">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading">Selected Publications</h2>
          <br> <br>
        </div>
      </div>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/cvpr20_controlimcap.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Say as You Wish: Fine-grained Control of Image Caption Generation with Abstract Scene Graphs</h5>
          <b>Shizhe Chen</b>, Qin Jin, Peng Wang, Qi Wu
          <br>
          CVPR, 202O <strong>(Oral)</strong> <br>
          [<a target="_blank" href="">PDF</a>] [<a target="_blank" href="">Code</a>]
          <br>
        </div>
      </div>

      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/cvpr20_t2vret.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning</h5>
          <b>Shizhe Chen</b>, Yida Zhao, Qin Jin, Qi Wu
          <br>
          CVPR, 2020 <br>
          [<a target="_blank" href="">PDF</a>] [<a target="_blank" href="">Code</a>]
          <br>
        </div>
      </div>

      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/mm19_storyboard.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Neural Storyboard Artist: Visualizing Stories with Coherent Image Sequences</h5>
          <b>Shizhe Chen</b>, Bei Liu, Jianlong Fu, Ruihua Song, Qin Jin, Pingping Lin, Xiaoyu Qi, Chunting Wang, Jin Zhou
          <br>
          ACM Multimedia, 2019 <strong>(Oral)</strong><br>
          [<a target="_blank" href="https://dl.acm.org/citation.cfm?id=3350571">PDF</a>] [<a target="_blank" href="https://github.com/cshizhe/neuralstoryboard">Data</a>]
          <br>
        </div>
      </div>

      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/ijcai19_sent_translation.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">From words to sentence: A progressive learning approach for zero-resource machine translation with visual pivots</h5>
          <b>Shizhe Chen</b>, Qin Jin, Jianlong Fu
          <br>
          IJCAI, 2019 <br>
          [<a target="_blank" href="https://arxiv.org/abs/1906.00872">PDF</a>]
          <br>
        </div>
      </div>

      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/aaai19_word_translation.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal Data</h5>
          <b>Shizhe Chen</b>, Qin Jin, Alexander Hauptmann
          <br>
          AAAI, 2019 <br>
          [<a target="_blank" href="https://arxiv.org/abs/1906.00378">PDF</a>]
          <br>
        </div>
      </div>
      
      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/mm19_crosslingual_imgcaption.png" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards</h5>
          Yuqing Song, <b>Shizhe Chen</b>, Qin Jin
          <br>
          ACM Multimedia, 2019 <strong>(Oral)</strong><br>
          [<a target="_blank" href="https://arxiv.org/abs/1908.05407">PDF</a>]
          <br>
        </div>
      </div>

      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/mm19_visualrelation.png" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Visual Relation Detection with Multi-Level Attention</h5>
          Sipeng Zheng, <b>Shizhe Chen</b>, Qin Jin
          <br>
          ACM Multimedia, 2019 <br>
          [<a target="_blank" href="https://dl.acm.org/citation.cfm?id=3350962">PDF</a>]
          <br>
        </div>
      </div>

      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/emnlp19_youmakeup.png" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension</h5>
          Weiying Wang, Yongcheng Wang, <b>Shizhe Chen</b>, Qin Jin
          <br>
          EMNLP, 2019 <br>
          [<a target="_blank" href="https://www.aclweb.org/anthology/D19-1517/">PDF</a>][<a target="_blank" href="https://github.com/AIM3-RUC/YouMakeup">Data</a>]
          <br>
        </div>
      </div>
      
      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/tmm19_topic_vidcap.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Generating Video Descriptions with Latent Topic Guidance</h5>
          <b>Shizhe Chen</b>, Qin Jin, Jia Chen, Alexander Hauptman
          <br>
          TMM, 2019 <br>
          [<a target="_blank" href="https://ieeexplore.ieee.org/document/8629976/">PDF</a>]
          <br>
        </div>
      </div>
      
      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/icmr18_audio.jpg" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Class-aware Self-attention for Audio Event Recognition</h5>
          <b>Shizhe Chen</b>, Jia Chen, Qin Jin, Alexander Hauptman
          <br>
          ICMR, 2018 <strong>(Best Paper Runner-up)</strong> <br>
          [<a target="_blank" href="https://dl.acm.org/citation.cfm?id=3206067">PDF</a>]
          <br>
        </div>
      </div>
      
      <br> <br>

      <div class="row" id="seq">
        <div class="col-md-3 panel">
          <img src="./img/pubs/mm16_emotion_modfusion.png" width="100%" height="100px">
        </div>
        <div class="col-md-9">
          <h5 class="text-muted">Multi-modal Conditional Attention Fusion for Dimensional Emotion Prediction</h5>
          <b>Shizhe Chen</b>, Qin Jin
          <br>
          ACM Multimedia, 2016<br>
          [<a target="_blank" href="https://arxiv.org/abs/1709.02251">PDF</a>]
          <br>
        </div>
      </div>
      
      <br> <br>

      <div class="row" id="seq">
        <h5 class="text-muted text-center"><a target="_blank" href="https://scholar.google.com/citations?user=wZhRRy0AAAAJ&hl=en">Go to Google Scholar for full publication list</a></h5>
      </div>
      

    </div>
  </section>

  <!-- Awards -->
  <section class="page-section" id="awards">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
            <h2 class="section-heading">Awards & Honors</h2>
        </div><br> <br>
      </div>

      <ul class="col-lg-12 text-muted">
        <li>2019 Zhijiang Cup Global AI Competition Video Captioning Challenge (First Prize)</li>
        <li>2019 ICCV VATEX Video Captioning Task (Second Place & Outstanding Method Award)</li>
        <li>2019 CVPR ActivityNet Dense Video Captioning Task (Winner)</li>
        <li>2019 TRECVID (Video to Text Description) Grand Challenge (Rank 1st)</li>
        <li>2019 AVEC Workshop Audio-Visual Cross-culture Emotion Challenge (Rank 1st)</li>
        <li>2018 CVPR ActivityNet Dense Video Captioning Task (Winner)</li>
        <li>2018 TRECVID (Video to Text Description) Grand Challenge (Rank 1st)</li>
        <li>2018 AVEC Workshop Audio-Visual Dimensional Emotion Challenge (Rank 1st)</li>
        <li>2017 TRECVID (Video to Text Description) Grand Challenge (Rank 1st)</li>
        <li>Best Grand Challenge Paper Award at ACM Multimedia 2017</li>
        <li>2017 ACM Multimedia (Video to Language) Grand Challenge (Rank 1st)</li>
        <li>2017 AVEC Workshop Audio-Visual Dimentional Emotion Challenge (Rank 1st)</li>
        <li><b>2017 Baidu Scholarship (10 Ph.D student worldwide)</b></li>
        <li>2016 MediaEval Emotion Impact of Movies Subtask (Ranked 1st)</li>
        <li>National Scholarship for Ph.D. Students in 2016.</li>
        <li>ACM Multimedia 2016 Student Travel Grant.</li>
        <li>National Scholarship for Undergraduate Students in 2013.</li>
    </ul>

    </div>
  </section>

  <!-- Services -->
  <section class="page-section" id="services">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
            <h2 class="section-heading">Services</h2>
        </div><br> <br>
      </div>

      <div class="row" id="seq">
        <div class="col-lg-12">
          <h5 class="text-muted">Journal Reviewer</h5>
          IEEE Transactions on Multimedia (TMM) <br>
          ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) <br>
          Multimedia Tools and Applications (MTA) <br>
          IEEE Access <br>
        </div>
      </div>

      <br>

      <div class="row" id="seq">
        <div class="col-lg-12">
          <h5 class="text-muted">Conference Reviewer</h5>
          ACM International Conference on Multimedia (ACM MM) <br>
          AAAI Conference on Artificial Intelligence (AAAI) <br>
        </div>
      </div>
    </div>
  </section>


  
  

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="row align-items-center">
        <div class="col-md-4">
          <span class="copyright">Copyright &copy; Shizhe Chen 2019</span>
        </div>
        <!-- <div class="col-md-4">
          <ul class="list-inline social-buttons">
            <li class="list-inline-item">
              <a href="#">
                <i class="fab fa-twitter"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="#">
                <i class="fab fa-facebook-f"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="#">
                <i class="fab fa-linkedin-in"></i>
              </a>
            </li>
          </ul>
        </div>
        <div class="col-md-4">
          <ul class="list-inline quicklinks">
            <li class="list-inline-item">
              <a href="#">Privacy Policy</a>
            </li>
            <li class="list-inline-item">
              <a href="#">Terms of Use</a>
            </li>
          </ul>
        </div> -->
      </div>
    </div>
  </footer>


  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Contact form JavaScript -->
  <script src="js/jqBootstrapValidation.js"></script>
  <script src="js/contact_me.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/agency.min.js"></script>

</body>

</html>
